import{_ as u}from"./chunks/ArticleMetadata.CUS63Ppn.js";import{_ as h,m as o,a as m,e as r,x as s,u as i,B as y,ah as f,o as n,p,q as w}from"./chunks/framework.BuAcqOzq.js";import"./chunks/theme.guJm1vuK.js";const N=JSON.parse('{"title":"System Design","description":"","frontmatter":{"title":"System Design","author":"ChocolateAceCream","date":"2024/05/04 10:24","categories":["System Design"],"tags":["System Design"]},"headers":[],"relativePath":"courses/SystemDesign/index.md","filePath":"courses/SystemDesign/index.md","lastUpdated":1741632211000}'),g={name:"courses/SystemDesign/index.md"},_={id:"system-design-key-points-summary",tabindex:"-1"},S=r("a",{class:"header-anchor",href:"#system-design-key-points-summary","aria-label":'Permalink to "System Design Key Points Summary <Badge text="System" type="warning" />"'},"​",-1),b=f('<h2 id="identify-the-trade-off" tabindex="-1">Identify the trade-off <a class="header-anchor" href="#identify-the-trade-off" aria-label="Permalink to &quot;Identify the trade-off&quot;">​</a></h2><h3 id="case-study-youtube-video" tabindex="-1">Case Study: Youtube Video <a class="header-anchor" href="#case-study-youtube-video" aria-label="Permalink to &quot;Case Study: Youtube Video&quot;">​</a></h3><p>When storing a video&#39;s meta data into mongoDB, one wise choice is to embedded video&#39;s uploader user info in the same collection. So each time video meta info is read, no need to join user&#39;s table. One drawback is updating user&#39;s info, now it need to upload all certain user&#39;s videos&#39; meta data (which has user&#39;s info embedded). However, we can do it async since it&#39;s no big deal for a few seconds/minutes delay for the update (so viewer might see older info of video uploader), that&#39;s the trade-off.</p><h3 id="case-study-twitter" tabindex="-1">Case Study: twitter <a class="header-anchor" href="#case-study-twitter" aria-label="Permalink to &quot;Case Study: twitter&quot;">​</a></h3><ol><li><p>Twitter is a read heavy system, so we can use read-only replicates of our DB. And since twitter includes follower/followee relations, better use relational DB and sharding. Even though sometimes write take place and may cause few seconds delay to the sharding, it&#39;s still a good trade-off.</p></li><li><p>The CDN usage. CND should be able to pull the S3 object storage for videos/images</p></li><li><p>Identify the key. Always considering what is the best field to used as a key to sharding/index. We want all twitters for one user go to one DB replicates. That&#39;s why we should use UID to sharding. For indexing of following table, since it&#39;s read heavy, it&#39;s way more frequently for a guy to track all ppl he followed rather than all guys that follow him. So we use follower as index.</p></li><li><p>For a recommendation twitters list, since 60% of ppl are active, we can generate the list asyncly for all users (or better, for ppl who logged in last 30 days). For example, when a new twitter generated, we push it to the message queue, and a worker will asyncly process the new twitter and put into feed cache</p></li></ol>',5);function D(e,v,x,k,C,B){const d=o("Badge"),l=u,c=o("ClientOnly");return n(),m("div",null,[r("h1",_,[s("System Design Key Points Summary "),i(d,{text:"System",type:"warning"}),s(),S]),i(c,null,{default:y(()=>{var t,a;return[(((t=e.$frontmatter)==null?void 0:t.aside)??!0)&&(((a=e.$frontmatter)==null?void 0:a.showArticleMetadata)??!0)?(n(),p(l,{key:0,article:e.$frontmatter},null,8,["article"])):w("",!0)]}),_:1}),b])}const V=h(g,[["render",D]]);export{N as __pageData,V as default};
