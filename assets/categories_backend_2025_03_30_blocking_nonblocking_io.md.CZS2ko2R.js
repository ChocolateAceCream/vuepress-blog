import{_ as h}from"./chunks/ArticleMetadata.VNjEmVR6.js";import{_ as u,m as t,a as g,e as s,x as a,u as i,B as k,ah as b,o as r,p,q as m}from"./chunks/framework.BuAcqOzq.js";import"./chunks/theme.BrlMw622.js";const T=JSON.parse('{"title":"Blocking / Non-blocking IO","description":"","frontmatter":{"title":"Blocking / Non-blocking IO","author":"ChocolateAceCream","date":"2025/03/30 19:00","isTop":false,"categories":["backend"],"tags":["Ruby on Rails","Nodejs","Go"]},"headers":[],"relativePath":"categories/backend/2025/03/30/blocking_nonblocking_io.md","filePath":"categories/backend/2025/03/30/blocking_nonblocking_io.md","lastUpdated":1743458943000}'),_={name:"categories/backend/2025/03/30/blocking_nonblocking_io.md"},w={id:"blocking-vs-non-blocking-io",tabindex:"-1"},f=s("a",{class:"header-anchor",href:"#blocking-vs-non-blocking-io","aria-label":'Permalink to "Blocking Vs. Non-blocking IO <Badge text="Go" type="warning" />"'},"​",-1),y=b('<p>The main difference is that blocking IO means when waiting for IO, whole program execution wait there doing nothing. while in non-blocking case, when IO blocks, a schedule will switch to other part of the program and keep running, then check back the status of blocked IO.</p><h2 id="ruby-on-rails-semi-non-blocking-io" tabindex="-1">Ruby on Rails (Semi-non-blocking io) <a class="header-anchor" href="#ruby-on-rails-semi-non-blocking-io" aria-label="Permalink to &quot;Ruby on Rails (Semi-non-blocking io)&quot;">​</a></h2><p>Since the present of global Interpreter lock (GIL), only one thread can run ruby code at a time, which means CPU-bound work is blocked if one thread is running some heavy computations. Imagine you have three threads running by puma, one threads is waiting for a DB query, then puma can switch to second thread and handle another request. Then, second request is handled and wait for DB query (1st request are still waiting as well), now puma can switch to 3rd thread to handle another request. However, only one thread can do CPU-bound work at one time.</p><h2 id="go-routine" tabindex="-1">Go routine <a class="header-anchor" href="#go-routine" aria-label="Permalink to &quot;Go routine&quot;">​</a></h2><p>Go routine support pure non-blocking IO. Multiple threads can execute go at same time, if any go routine waiting for IO, then schedule will switch to next go routine to run on the thread. That&#39;s why go is very good at concurrency</p><h2 id="nodejs-event-loop" tabindex="-1">Nodejs event loop <a class="header-anchor" href="#nodejs-event-loop" aria-label="Permalink to &quot;Nodejs event loop&quot;">​</a></h2><p>Nodejs is single thread, but using non-blocking IO, so CPU work blocks the entire event loop (no parallelism) One workaround is to use worker threads to offload CPU tasks to separate threads (which run CPU heavy jobs on other thread thus make it a IO waiting event)</p>',7);function I(e,v,O,N,B,C){const l=t("Badge"),c=h,d=t("ClientOnly");return r(),g("div",null,[s("h1",w,[a("Blocking Vs. Non-blocking IO "),i(l,{text:"Go",type:"warning"}),a(),f]),i(d,null,{default:k(()=>{var o,n;return[(((o=e.$frontmatter)==null?void 0:o.aside)??!0)&&(((n=e.$frontmatter)==null?void 0:n.showArticleMetadata)??!0)?(r(),p(c,{key:0,article:e.$frontmatter},null,8,["article"])):m("",!0)]}),_:1}),y])}const V=u(_,[["render",I]]);export{T as __pageData,V as default};
